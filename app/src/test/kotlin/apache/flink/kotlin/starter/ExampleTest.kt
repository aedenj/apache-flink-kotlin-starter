/*
 * This Kotlin source file was generated by the Gradle 'init' task.
 */
package apache.flink.kotlin.starter

import kafka.server.`KafkaConfig$`
import net.mguenther.kafka.junit.EmbeddedKafkaCluster
import net.mguenther.kafka.junit.EmbeddedKafkaCluster.provisionWith
import net.mguenther.kafka.junit.EmbeddedKafkaClusterConfig.newClusterConfig
import net.mguenther.kafka.junit.EmbeddedKafkaConfig.brokers
import net.mguenther.kafka.junit.ObserveKeyValues.on
import net.mguenther.kafka.junit.SendValues.to
import net.mguenther.kafka.junit.TopicConfig
import org.assertj.core.api.Assertions.*
import org.junit.jupiter.api.*
import org.junit.jupiter.api.extension.ExtendWith
import uk.org.webcompere.systemstubs.environment.EnvironmentVariables
import uk.org.webcompere.systemstubs.jupiter.SystemStub
import uk.org.webcompere.systemstubs.jupiter.SystemStubsExtension
import org.apache.flink.core.execution.JobClient


@ExtendWith(SystemStubsExtension::class)
@DisplayName("Example Test")
class ExampleTest {
    @SystemStub
    private lateinit var environment: EnvironmentVariables
    private val kafka:EmbeddedKafkaCluster = provisionWith(newClusterConfig().configure(
        brokers().with(`KafkaConfig$`.`MODULE$`.ListenersProp(), "PLAINTEXT://localhost:65438"))
    )
    private lateinit var job:JobClient

    init {
        kafka.start()
        kafka.send(to("source","a", "b", "c"))
    }

    @BeforeAll
    fun setup() {
        environment.set("FLINK_ENV", "test")
        job = main().executeAsync()
    }

    @AfterAll
    fun tearDown() {
        job.cancel()
        kafka.stop()
    }

    @Test
    fun `three messages are consumed and produced`() {
        kafka.observe(on("destination", 3))
    }
}
